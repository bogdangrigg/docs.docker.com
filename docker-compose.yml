data:
    image: busybox
    command: "true"
    volumes:
        - /docs
        - /public

fetch:
    build: .
    command: |
        /bin/bash -ec " \
        python fetch_content.py /docs all-projects.yml
        ./touch-up.sh /docs
        "
    volumes_from:
        - data
    environment:
        - GITHUB_USERNAME
        - GITHUB_TOKEN

build:
    build: .
    command: /bin/bash -ec "hugo -d /public/$DOCS_VERSION"
    working_dir: /docs
    volumes_from:
        - data
    environment:
        - DOCS_VERSION

upload:
    build: .
    working_dir: /public
    command: |
        /bin/bash -c ' \
        if [ -n "$CLEAN" ] ; then
          aws s3 rm --recursive s3://$AWS_S3_BUCKET/$CLEAN
        fi
        aws s3 sync --acl=public-read . s3://$AWS_S3_BUCKET
        '
    volumes_from:
        - data
    environment:
        - CLEAN
        - AWS_ACCESS_KEY_ID
        - AWS_SECRET_ACCESS_KEY
        - AWS_S3_BUCKET

serve:
    build: .
    working_dir: /docs
    command: /bin/bash -c "hugo server -d /public --port=8000 --baseUrl=$HUGO_BASE_URL --bind=$HUGO_BIND_IP"
    environment:
        - HUGO_BASE_URL
        - HUGO_BIND_IP
    ports:
        - "8000:8000"
    volumes_from:
        - data

test:
    build: .
    working_dir: /docs
    command: |
        /bin/bash -c " \
        URL=http://$HUGO_BASE_URL:8000
        hugo server -d /public --port=8000 --baseUrl=$HUGO_BASE_URL --bind=$HUGO_BIND_IP &
        until curl --fail --silent $URL ; do \
          sleep 1 ; \
        done
        exec python /src/docvalidate.py $URL
        "
    environment:
        - HUGO_BASE_URL
        - HUGO_BIND_IP
    ports:
        - "8000:8000"
    volumes_from:
        - data
